{
	"llm_config": {
		"model_name": "HuggingFaceTB/SmolLM-135M-Instruct",
		"system_message": "You are a helpful assistant. Provide brief, direct answers in a chat interface.",
		"max_length": 128,
		"min_length": 8,
		"temperature": 0.7,
		"top_k": 50,
		"top_p": 0.9,
		"no_repeat_ngram_size": 3,
		"max_new_tokens": 64,
		"device": "cpu",
		"model_path": "./Model",
		"finetune_config": {
			"epochs": 10,
			"batch_size": 8,
			"learning_rate": 0.001,
			"weight_decay": 0.01,
			"eval_strategy": "epoch",
			"save_strategy": "epoch",
			"logging_steps": 500,
			"lora_config": {
				"task_type": "CAUSAL_LM",
				"r": 4,
				"lora_alpha": 32,
				"lora_dropout": 0.01,
				"target_modules": [
					"q_proj"
				]
			}
		}
	},
	"backend_config": {
		"cors_origins": "http://localhost:4200",
		"port": 5000,
		"debug": true
	},
	"frontend_config": {
		"api_url": "http://localhost:5000"
	}
}